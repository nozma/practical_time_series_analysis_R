---
title: "2章 時系列データの見つけ方と前処理"
author: '@nozma'
date: "2022-08-17"
output: html_document
---

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)
```

## 2.2 表データの集合から時系列データの集合を作成する

- 書籍のGitHubリポジトリからデータ読み込み。
- 以下の調整を行った。
  - `user`、`emailsOpens`は整数型に変換。
  - `week`は日付型に変換。

```{r}
yearJoined <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/year_joined.csv",
  col_types = "ici"
)
emails <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/emails.csv",
  col_types = "nnT"
) %>% 
  mutate(
    emailsOpened = as.integer(emailsOpened),
    user = as.integer(user),
    week = as.Date(week)
  )
donations <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/donations.csv",
  col_types = "nTn"
) %>% mutate(user = as.integer(user))
```

### 2.2.1 事例：収集した時系列データを組み立てる

#### p.25 `yearJoined`のレコードが会員毎に何件あるかを確認する

```{r}
yearJoined %>% count(user) %>% distinct(n)
```

#### p.26 ユーザーがメールを開いていない週のレコードが存在するかどうかを確認する

まず、0件のデータがないことを確認。

```{r}
emails %>% filter(emailsOpened < 1)
```

次に特定のユーザーのデータを見て、欠損があることを確認。

- 書籍では生のデータを確認していたが、日付の差分をとり間隔が7日ではないデータが存在することを確認した。
- 日付の範囲から期待されるレコード数を求める方法は直感的ではなく間違いにつながる可能性(※)があるため略。
  - ※意図しないレコードが挿入されていたり、レコードが重複しているような場合を発見できない可能性がある。

```{r}
emails %>% 
  filter(user == 998) %>% 
  arrange(week) %>% 
  mutate(diff = week - lag(week)) %>% 
  count(diff)
```

#### p.27 会員データの欠損週を埋める

書籍では日付とユーザーIDの直積を求め、それをインデックスに設定する形で欠損週のデータを生成している。

しかし、これには次のような課題がある。

- すべてのユーザーがメールを開かなかった週が存在する場合、その週は欠損したままである。
- ユーザーごとに先頭・末尾に不要なレコードが生ずるため、処理が手間である。
  - 書籍では、これを後の作業で取り除いている。

そこで、次のように行った。

- ユーザーごとに`week`の最大・最小を求める。
- `purrr::map2`で1週間ごとの日付を生成し、`tidyr::unnest`で展開。
- 元のデータを再度結合し、`tidyr::replace_na`でNAを0に置換。

```{r}
emails %>% 
  group_by(user) %>% 
  # ユーザーごとに最大・最小の日付を取得
  summarise(
    start_date = min(week), 
    end_date = max(week)
  ) %>% 
  # 最大・最小の範囲から1週間ごとの日付を生成
  mutate(
    week = map2(start_date, end_date, ~seq(.x, .y, by = "1 week"))
  ) %>% 
  unnest(week) %>% 
  select(user, week) %>% 
  # emailsデータを結合してNAを0で置換
  left_join(emails, by = c("user", "week")) %>% 
  replace_na(list(emailsOpened = 0)) -> all_email
```

### 2.2.2 発掘した時系列の構築

#### p.30 寄付額データを1週間単位に変換

`lubridate::round_date`でタイムスタンプを1週間単位にしてから集約。

```{r}
donations %>% 
  mutate(
    week = ceiling_date(timestamp, unit = "week", week_start = 1)
  ) %>% 
  group_by(user, week) %>% 
  summarise(
    amount = sum(amount),
    .groups = "drop"
  ) -> agg_donations
```

#### p.30-31 メール開封データと寄付額データを結合する

書籍のPythonコードはかなり修正しないと動かなかった。

p.31でターゲット変数のシフトも行っているので、それもついでに実施する。

```{r}
all_email %>% 
  left_join(agg_donations, by = c("user", "week")) %>% 
  group_by(user) %>% 
  mutate(
    target = lag(amount)
  ) %>% 
  replace_na(list(amount = 0, target = 0)) -> merged_df
```

```{r}
merged_df %>% 
  filter(user == 998)
```

