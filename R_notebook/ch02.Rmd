---
title: "2章 時系列データの見つけ方と前処理"
author: '@nozma'
date: "2022-08-17"
output: html_document
---

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)
library(ggplot2)
theme_set(theme_bw())
```

## 2.2 表データの集合から時系列データの集合を作成する

- 書籍のGitHubリポジトリからデータ読み込み。
- 以下の調整を行った。
  - `user`、`emailsOpens`は整数型に変換。
  - `week`は日付型に変換。

```{r}
yearJoined <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/year_joined.csv",
  col_types = "ici"
)
emails <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/emails.csv",
  col_types = "nnT"
) %>% 
  mutate(
    emailsOpened = as.integer(emailsOpened),
    user = as.integer(user),
    week = as.Date(week)
  )
donations <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/donations.csv",
  col_types = "nTn"
) %>% mutate(user = as.integer(user))
```

### 2.2.1 事例：収集した時系列データを組み立てる

#### p.25 `yearJoined`のレコードが会員毎に何件あるかを確認する

```{r}
yearJoined %>% count(user) %>% distinct(n)
```

#### p.26 ユーザーがメールを開いていない週のレコードが存在するかどうかを確認する

まず、0件のデータがないことを確認。

```{r}
emails %>% filter(emailsOpened < 1)
```

次に特定のユーザーのデータを見て、欠損があることを確認。

- 書籍では生のデータを確認していたが、日付の差分をとり間隔が7日ではないデータが存在することを確認した。
- 日付の範囲から期待されるレコード数を求める方法は直感的ではなく間違いにつながる可能性(※)があるため略。
  - ※意図しないレコードが挿入されていたり、レコードが重複しているような場合を発見できない可能性がある。

```{r}
emails %>% 
  filter(user == 998) %>% 
  arrange(week) %>% 
  mutate(diff = week - lag(week)) %>% 
  count(diff)
```

#### p.27 会員データの欠損週を埋める

書籍では日付とユーザーIDの直積を求め、それをインデックスに設定する形で欠損週のデータを生成している。

しかし、これには次のような課題がある。

- すべてのユーザーがメールを開かなかった週が存在する場合、その週は欠損したままである。
- ユーザーごとに先頭・末尾に不要なレコードが生ずるため、処理が手間である。
  - 書籍では、これを後の作業で取り除いている。

そこで、次のように行った。

- ユーザーごとに`week`の最大・最小を求める。
- `purrr::map2`で1週間ごとの日付を生成し、`tidyr::unnest`で展開。
- 元のデータを再度結合し、`tidyr::replace_na`でNAを0に置換。

```{r}
emails %>% 
  group_by(user) %>% 
  # ユーザーごとに最大・最小の日付を取得
  summarise(
    start_date = min(week), 
    end_date = max(week)
  ) %>% 
  # 最大・最小の範囲から1週間ごとの日付を生成
  mutate(
    week = map2(start_date, end_date, ~seq(.x, .y, by = "1 week"))
  ) %>% 
  unnest(week) %>% 
  select(user, week) %>% 
  # emailsデータを結合してNAを0で置換
  left_join(emails, by = c("user", "week")) %>% 
  replace_na(list(emailsOpened = 0)) -> all_email
```

### 2.2.2 発掘した時系列の構築

#### p.30 寄付額データを1週間単位に変換

`lubridate::round_date`でタイムスタンプを1週間単位にしてから集約。

```{r}
donations %>% 
  mutate(
    week = ceiling_date(timestamp, unit = "week", week_start = 1)
  ) %>% 
  group_by(user, week) %>% 
  summarise(
    amount = sum(amount),
    .groups = "drop"
  ) -> agg_donations
```

#### p.30-31 メール開封データと寄付額データを結合する

書籍のPythonコードはかなり修正しないと動かなかった。

p.31でターゲット変数のシフトも行っているので、それもついでに実施する。

```{r}
all_email %>% 
  left_join(agg_donations, by = c("user", "week")) %>% 
  group_by(user) %>% 
  mutate(
    target = lag(amount)
  ) %>% 
  replace_na(list(amount = 0, target = 0)) -> merged_df
```

```{r}
merged_df %>% 
  filter(user == 998)
```

## 2.4 データのクリーニング

### 2.4.1 欠損値の処理

#### p.38 データの準備

もともとRのコードだが、本文のコードは下から2行目が誤っている。

- 誤: `high.unemp.idx <- sample(high.unemp.idx,)`
- 正: `high.unemp.idx <- sample(high.unemp.idx, num.to.select)`

その他の記述もやや冗長なので書き直した。

```{r}
unemp <- read_csv(
  "https://raw.githubusercontent.com/PracticalTimeSeriesAnalysis/BookRepo/master/Ch02/data/UNRATE.csv",
  col_types = "Dn"
)

# 無作為に欠損させたデータセットを生成する
set.seed(778)
unemp %>% 
  slice_sample(prop = 0.9) -> rand_unemp

# 失業率が高い月に欠損している確率が高いデータセットを生成する
unemp %>% 
  anti_join(
    # 失業率8を超えるレコードの20%を抽出し、anti_joinで除外
    unemp %>% filter(UNRATE > 8) %>% slice_sample(prop = 0.2),
    by = c("DATE", "UNRATE")
  ) -> bias_unemp
```


#### p.40 欠損させたデータの日付とNAを補う

書籍ではrolling joinを使用しているが、使わなくとも可能かつ現行バージョンのdplyrではrolling joinができないので別の方法で埋める。

```{r}
all_dates <- seq(min(unemp$DATE), max(unemp$DATE), by = "1 month")
tibble(DATE = all_dates) %>% 
  left_join(rand_unemp, by = "DATE") %>% 
  mutate(missing = is.na(UNRATE)) -> rand_unemp
tibble(DATE = all_dates) %>% 
  left_join(bias_unemp, by = "DATE") %>% 
  mutate(missing = is.na(UNRATE)) -> bias_unemp
```


#### p.41-42 前方埋め

前方埋めをした上でp.41の作図まで行う。

```{r}
unemp %>% 
  mutate(group = "original") %>% 
  union_all(
    rand_unemp %>% 
      fill(UNRATE, .direction = "down") %>% # 前方埋め
      mutate(group = "random missing")
  ) %>% 
  ggplot(aes(x = DATE, y = UNRATE, color = group)) +
  geom_line() +
  geom_point(data = . %>% filter(missing)) +
  lims(x = c(ymd("1977/01/01"), ymd("1981/12/31")))
```
p.42の作図

```{r}
unemp %>% 
  rename(original = UNRATE) %>% 
  left_join(
    rand_unemp %>% 
      fill(UNRATE, .direction = "down") %>% # 前方埋め
      rename(random_missing = UNRATE),
    by = "DATE"
  ) %>% 
  ggplot(aes(x = original, y = random_missing, color = missing)) +
  geom_point()
```


